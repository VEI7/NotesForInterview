# CV

## Pooling的作用

(1) 增大感受野

所谓感受野，即一个像素对应回原图的区域大小，假如没有pooling，一个3*3，步长为1的卷积，那么输出的一个像素的感受野就是3*3的区域，再加一个stride=1的3*3卷积，则感受野为5*5，我们看左上角像素的传播就明白了。

(2) 增加平移不变性

我们希望目标的些许位置的移动，能得到相同的结果。因为pooling不断地抽象了区域的特征而不关心位置，所以pooling一定程度上增加了平移不变性。

(3) 使网络更容易优化，pooling是每个featuremap单独做降采样。

## 

## 图像处理中锐化和平滑的操作

### 参考回答：

锐化就是通过增强高频分量来减少图像中的模糊,在增强图像边缘的同时也增加了图像的噪声。

平滑与锐化相反,过滤掉高频分量,减少图像的噪声是图片变得模糊。

## ● VGG使用3*3卷积核的优势是什么?

### 参考回答：

2个3*3的卷积核串联和5*5的卷积核有相同的感知野,前者拥有更少的参数。多个3*3的卷积核比一个较大尺寸的卷积核有更多层的非线性函数,增加了非线性表达,使判决函数更具有判决性。

## 什么是Group Convolution

### 参考回答：

若卷积神将网络的上一层有N个卷积核,则对应的通道数也为N。设群数目为M,在进行卷积操作的时候,将通道分成M份,每个group对应N/M个通道,然后每个group卷积完成后输出叠在一起,作为当前层的输出通道。

## 在深度学习中，通常会finetuning已有的成熟模型，再基于新数据，修改最后几层神经网络权值，为什么？

### 参考回答：

实践中的数据集质量参差不齐，可以使用训练好的网络来进行提取特征。把训练好的网络当做特征提取器。

## Caffe：整体架构说一下，新加一个层需要哪些步骤，卷积是怎么实现的，多卡机制，数据并行还是模型并行？

### 参考回答：

Caffe是深度学习的一个框架，Caffe框架主要包括五个组件：Blob、Solver、Net、Layer、Proto；框架结构如下图所示。这五大组件可以分为两个部分：第一部分，Blob、Layer和Net，这三个组件使得Caffe构成基于自己的模块化的模型，caffe是逐层地定义一个net，而net是从数据输入层到损失曾自下而上定义整个模型，Blob在caffe中是处理和传递实际数据的数据封装包；第二部分：Solver和Proto，这两个模型分别用于协调模型的优化以及用于网络模型的结构定义、存储和读取的方式（Layer-By-Layer）定义Net，而贯穿所有Nets的结构就是caffe框架或模型；对于Layer而言，输入的是Blob数据封装包格式的实际数据，当采用该框架进行训练时，也就是Solver调优模型，则需要Proto这种网络模型的结构定义、存储和读取。

总体来说，caffe是通过Layer

Caffe中卷积运算的原理

俗话说，一图胜千言，首先先给出原理示意图，为了方便理解，这里以二维核为例

![img](https://uploadfiles.nowcoder.com/images/20190317/311436_1552829076864_F8E55950D39A06E4B902B0E54A3E1CD0)

滑动窗口在图像中每滑动一个地方，将图像中该滑动窗口图像展开为一列，所有列组成图中的滑动窗口矩阵，这里假设pad=1,stride=1,K=3,则滑动窗口矩阵每行大小为W*H,一共K*K行.

每个核展开为一行，N个核形成的核矩阵大小为N*K*K。

最后将核矩阵和滑动窗口矩阵相乘，每一行就是一个特征图，N个卷积核形成N个特征图。

扩展到三维核

![img](https://uploadfiles.nowcoder.com/images/20190317/311436_1552829055228_E0FC5FD42B3D94C80FF5ADB3F09572FC)

![img](https://uploadfiles.nowcoder.com/images/20190317/311436_1552829034487_5F1C70CA15CA4841A91AECB99701C8AD)

三维核就是多了一个通道的概念，原理与二维核一样。

caffe支持多GPU并行了，原理比较简单，就是每个GPU分别算一个batch，n个GPU，实际的batchsize就是n*batch，比如原来用一个GPU，batchsize设置成256，现在用4个GPU，把batchsize设置成64，和原来的一个GPU的运算是等价的。

实际使用的时候基本不用设置，和原来一样编译好就可以用了。命令就是在-gpu 后面对多个GPU号用逗号隔开，比如-gpu 1,2,3,4 就是同时使用1-4共4个GPU，GPU编号可以不连续，或者直接用-gpu all，就是使用所有的GPU。

Caffe是数据并行的。

## GAN网络的思想

### 参考回答：

GAN用一个生成模型和一个判别模型,判别模型用于判断给定的图片是不是真实的图片,生成模型自己生成一张图片和想要的图片很像,开始时两个模型都没有训练,然后两个模型一起进行对抗训练,生成模型产生图片去欺骗判别模型,判别模型去判别真假,最终两个模型在训练过程中,能力越来越强最终达到稳态。

## 1*1的卷积作用

### 参考回答：

实现跨通道的交互和信息整合,实现卷积核通道数的降维和升维,可以实现多个feature map的线性组合,而且可是实现与全连接层的等价效果。



