## 聚类算法



#### K-Means

算法的思想很简单，事先确定常数K，常数K意味着最终的聚类类别数，首先随机选定初始点为质心，并通过计算每一个样本与质心之间的相似度(这里为欧式距离)，将样本点归到最相似的类中，接着，重新计算每个类的质心(即为类中心)，重复这样的过程，知道质心不再改变，最终就确定了每个样本所属的类别以及每个类的质心。由于每次都要计算所有的样本与每一个质心之间的相似度，故在大规模的数据集上，K-Means算法的收敛速度比较慢。

初始化常数K，随机选取初始点为质心

重复计算一下过程，直到质心不再改变

计算样本与每个质心之间的相似度，将样本归类到最相似的类中

重新计算质心

输出最终的质心以及每个类



```python
#k-means伪代码
import numpy as np
import copy
#计算欧氏距离
def get_distance(X,Y):
	return np.sum((X-Y)**2)**0.5
def calc_mean(X): #计算中心点，每一维取均值
	l=len(X[0])
	list_mean=[]
	for i in range(l):
		s=0
		for j in X:
			s+=j[i]
		m=s/len(X)
		list_mean.append(m)
	return list_mean
 
def k_means(x_train,k,max_iter):
	num_iter = 0
	#初始簇中心
	cluster_center = x_train[:k]
	pre_cluster_center = copy.deep_copy(cluster_center) #上一次的簇中心点
	#开始迭代
	while num_iter<max_iter:
		#临时变量
		clusters_data={} #字典{簇下标：坐标}
		for i in x_train:
			cluster_dists=[]
			for index,cluster in enumerate(cluster_center):
				distance=get_distance(i,cluster)
				cluster_dists.append((index,distance)) #每个样本到中心点的距离
			
			cluster_dists.sort(key=lambda x:x[1]) #升序
			min_index,min_dist=cluster_dists[0] #取距离最近
			
			if min_index not in clusters_data:
				clusters_data[min_index]=[]
			clusters_data[min_index].append(i) #数据添加到临时变量中
			
		#更新簇中心点
		for index in clusters_data:
			cluster_center[index]=calc_mean(clusters_data[index])
		if pre_cluster_center == cluster_center:
			break   #如果簇中心点不再变化，那么结束
		else:
			pre_cluster_center = copy.deep_copy(cluster_center) #拷贝一下
	return cluster_center #返回最终的簇中心点
```



#### DBSCAN

DBSCAN（Density-Based Spatial Clustering of Applications with Noise）聚类算法，它是一种基于高密度连通区域的、基于密度的聚类算法，能够将具有足够高密度的区域划分为簇，并在具有噪声的数据中发现任意形状的簇。我们总结一下DBSCAN聚类算法原理的基本要点：

DBSCAN 算法是一种基于密度的聚类算法： 　　

1.聚类的时候不需要预先指定簇的个数 　　

2.最终的簇的个数不确定

 DBSCAN算法将数据点分为三类： 　　

1.核心点：在半径Eps内含有超过MinPts数目的点。 　　

2.边界点：在半径Eps内点的数量小于MinPts,但是落在核心点的邻域内的点。 　　

3.噪音点：既不是核心点也不是边界点的点。

**DBSCAN算法的流程**

1.将所有点标记为核心点、边界点或噪声点； 

2.删除噪声点；

3.为距离在Eps之内的所有核心点之间赋予一条边； 

4.每组连通的核心点形成一个簇； 

5.将每个边界点指派到一个与之关联的核心点的簇中（哪一个核心点的半径范围之内）。

**DBSCAN和Kmeans的区别：**

1)K均值和DBSCAN都是将每个对象指派到单个簇的划分聚类算法，但是K均值一般聚类所有对象，而DBSCAN丢弃被它识别为噪声的对象。

2)K均值很难处理非球形的簇和不同大小的簇。DBSCAN可以处理不同大小或形状的簇，并且不太受噪声和离群点的影响。当簇具有很不相同的密度时，两种算法的性能都很差。

3)K均值可以发现不是明显分离的簇，即便簇有重叠也可以发现，但是DBSCAN会合并有重叠的簇。

4)K均值算法的时间复杂度是O(m)，而DBSCAN的时间复杂度是O(m^2)，除非用于诸如低维欧几里得数据这样的特殊情况。

5)DBSCAN多次运行产生相同的结果，而K均值通常使用随机初始化质心，不会产生相同的结果。

6)DBSCAN自动地确定簇个数，对于K均值，簇个数需要作为参数指定。然而，DBSCAN必须指定另外两个参数：Eps（邻域半径）和MinPts（最少点数）。



