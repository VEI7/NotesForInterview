## 线性代数

#### 1. 求两个矩阵中向量的欧氏距离

假设有两个三维向量集，用矩阵表示:

![image-20200307150355839](/var/folders/dp/_cdw_jwj6xd7qlybydtwn6k80000gn/T/abnerworks.Typora/image-20200307150355839.png)



要求A，B两个集合中的元素两两间欧氏距离。

先求出$AB^T$：

![image-20200307150542095](/var/folders/dp/_cdw_jwj6xd7qlybydtwn6k80000gn/T/abnerworks.Typora/image-20200307150542095.png)

然后对A和$B^T$分别求其中每个向量的模平方，并扩展为2*3矩阵：

![image-20200307150729400](/var/folders/dp/_cdw_jwj6xd7qlybydtwn6k80000gn/T/abnerworks.Typora/image-20200307150729400.png)

![image-20200307150805098](/var/folders/dp/_cdw_jwj6xd7qlybydtwn6k80000gn/T/abnerworks.Typora/image-20200307150805098.png)

#### 2.PCA降维

PCA是比较常见的线性降维方法,通过线性投影将高维数据映射到低维数据中。PCA算法的具体操作为对所有的样本进行中心化操作,计算样本的协方差矩阵$A^T A$, 然后对协方差矩阵做奇异值分解,取最大的k个特征值对应的特征向量构造投影矩阵。也就是说我们可以用最大的k个特征值和特征向量来近似描述矩阵。

